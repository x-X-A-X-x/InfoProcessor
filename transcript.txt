Welcome to Jeremy’s IT Lab. This is a free,
complete course for the CCNA. If you like
these videos, please subscribe to follow along
with the series. Also, please like and leave
a comment, and share the video to help spread
this free series of videos. Thanks for your
help.
In this video we will continue our study of
QoS. Quality of Service. In part 1 we covered
voice VLANs and Power over Ethernet in the
first half, and then I briefly introduced
QoS in the second half. Hopefully you understand
the purpose of QoS, which is to prioritize
certain traffic such as voice and video traffic
to reduce the delay, jitter, and loss, and
also to ensure it gets the required bandwidth.
This time we’ll go more in depth about the
terms in exam topic 4.7, such as classification,
marking, queuing, congestion, policing, and
shaping. Note that you don’t need to know
QoS design and configuration for the CCNA.
As long as you understand the topics I introduce
in this video, you should be able to answer
QoS questions on the CCNA exam.
Here’s what we’ll cover in today’s video.
First, classification and marking. This is
how routers and switches identify which traffic
should be given higher priority. Then we’ll
cover queuing and congestion management. I
already introduced these in the previous video,
but let’s go more in depth. Finally shaping
and policing, two ways of controlling the
rate at which traffic enters or exits an interface.
Watch until the end of the video for a bonus
practice question from Boson Software’s
ExSim for CCNA, the best practice exams for
the CCNA.
Let’s begin with classification. As you
know, the purpose of QoS is to give certain
kinds of network traffic priority over others
during times of network congestion. Classification
organizes network traffic, meaning packets,
into traffic classes or categories. So, why
is that important for QoS? Classification
is fundamental to QoS. To give priority to
certain types of traffic, you have to identify
which types of traffic to give priority to.
So, how can we classify traffic? There are
many methods of classifying traffic. Here
are some examples. You can use an ACL. Traffic
permitted by the ACL will be given certain
treatment, for example it could be treated
as high-priority, and other traffic which
is denied by the ACL will not be given that
treatment. This is like how we used ACLs for
dynamic NAT. The ACL isn’t being used to
actually permit or deny traffic, it’s just
being used to identify certain traffic. There
is also NBAR, Network Based Application Recognition.
Sometimes just looking at the Lower-layer
information, such as the TCP or UDP port number
and IP address, isn’t enough to identify
exactly what kind of traffic it is. NBAR performs
what’s called a ‘deep packet inspection’
to look beyond the Layer 3 and 4 information
all the way up to Layer 7 to identify the
specific kind of traffic. However, we won’t
focus on methods like these in this video.
In the Layer 2 and Layer 3 headers there are
specific fields used for this purpose, for
the purpose of classifying traffic. I mentioned
them briefly in previous videos, but finally
let’s take a look at them. The PCP, priority
code point, field of the 802.1Q tag can be
used to identify high or low priority traffic.
Keep in mind that this field can only be used
when there is a dot1q tag, only when a VLAN
tag is added to the Ethernet header. Then
there is the DSCP, Differentiated Services
Code Point, field of the IP header. It can
also be used to identify high or lower priority
traffic. Okay, let’s take a look at each
of these.
First up, PCP. Here you can see an Ethernet
header with a dot1q tag, a VLAN tag. The PCP
field is in this dot1q tag. Here are the fields
of the dot1q tag that I showed you earlier
in the course, and the PCP field is this 3-bit
field here. Note that you might also hear
this field referred to as CoS, class of service.
Don’t mix it up with the entire concept
of QoS, CoS just refers to this part of the
dot1q tag. Its use is defined by IEEE 802.1p.
So, let’s see how it has been defined. Well,
there are 3 bits which gives 8 possible values,
0 to 7. This is how they are defined. You
probably don’t have to memorize all of these,
but I recommend remembering 0 for best effort,
3 for critical applications, 4 for video,
and 5 for voice. Regarding 0, best effort,
what does that mean? Best effort delivery
means there is no guarantee that data is delivered
or that it meets any QoS standard. It’s
regular traffic, not high-priority. This is
the default, by the way, regular traffic will
have a value of ‘0’ in the PCP field.
Since we talked about voice traffic a lot
in the previous video, let me point out something
about 3 and 5. IP phones mark their call signaling
traffic as PCP3. Call signaling traffic is
used to establish phone calls. However, when
the call is established, the actual voice
traffic itself, the audio packets, is marked
as PCP5. I put the term mark in bold because
it’s another important QoS term. Basically
to mark traffic is to set the value in the
PCP or DSCP fields. Then network devices look
at those markings and use them to classify
the traffic as high-priority, low-priority,
etc. So, when an IP phone marks its voice
traffic as PCP5, it’s because it wants the
routers and switches to classify those packets
as high-priority.
Here’s a simple network with a couple PCs
in VLAN10 and IP phones in VLAN20. I want
to demonstrate a very important point about
using PCP to classify traffic. Because the
PCP field is found in the dot1q header, it
can only be used over the following connection
types. First, the obvious one is trunk links.
Traffic sent over a trunk link is tagged with
dot1q, unless the traffic is in the native
VLAN, but let’s assume the native VLAN isn’t
being used. However, as I explained in the
previous video, voice traffic is tagged as
well even over access links. So, assuming
the network is configured so that all PCs
and phones can communicate with each other
as well as over the external network, which
of these links are either trunk links or access
links with a voice VLAN? Well, the connections
between the phones and the switches are access
ports with a voice VLAN. Traffic to and from
the phones will be tagged. And these two connections
will be trunk links, tagging traffic in VLAN
10 or 20. So, over these connections devices
can mark traffic with a specific PCP value
to tell other devices to treat the traffic
with a certain level of priority. And devices
receiving that marked traffic can classify
the traffic as high, medium, low, or whatever
priority based on the PCP marking. Let me
clarify that in this type of network design
traffic from the PCs is not tagged with dot1q
here, so it can’t have a PCP marking over
this link. In addition to that, all traffic
between R1 and R2, or between R2 and external
destinations will not have a dot1q tag. So,
traffic over those links cannot be marked
with a PCP value, PCP cannot be used to classify
traffic. So, that’s a major limitation of
using PCP, a limitation which the Layer 3
classification methods don’t have.
So now let’s look at how marking and classification
is done at Layer 3. In the IPv4 header there
is a byte that is referred to as the ToS byte,
Type of Service. IPv6 also has a byte called
the traffic class byte used for QoS, but let’s
focus on the IPv4 header. It’s this byte
here, the second one in the header after the
version and IHL fields. The modern use of
the ToS byte consists of two fields, DSCP,
differentiated services code point, and ECN,
explicit congestion notification. However,
previously this byte was organized differently.
Here’s the old use of the ToS byte. Three
bits were used for the IPP, IP Precedence,
field. It was used to mark packets according
to their priority, like the PCP field in the
dot1q header. The remaining 5 bits were mostly
defined for some other purpose, but my understanding
is that they weren’t really used. So, 3
bits once again gives 8 possible values here,
just like in the PCP field of the dot1q header.
However, the current use of the ToS byte,
the one shown above, is this. 6 bits for DSCP
and 2 for ECN. 6 bits in DSCP allows for a
total of 64 values, which gives a lot of flexibility
regarding how we can mark and classify traffic
in the network.
Before going in depth about DSCP, let’s
take a quick look at IPP. The standard IPP
markings are similar to PCP. 6 and 7 are reserved
for what’s called ‘network control’
traffic. That refers to traffic like OSPF
messages sent between routers. Interactive
voice traffic is marked as IPP 5, interactive
video traffic is marked as IPP 4, IPP 3 is
used for voice signaling traffic, for setting
up and tearing down phone calls. And IPP 0
is used for best effort traffic, regular data
traffic without any special requirements.
So, with 6 and 7 reserved, only 6 possible
values remain. Although 6 is sufficient for
many networks, the QoS requirements of some
more complex networks demand more flexibility.
And because IPP only used 3 bits of the ToS
byte and the other 5 largely weren’t used,
it was decided that an extra 3 bits would
be added to IPP to make DSCP, differentiated
services code point.
Now let’s take a look at DSCP. RFC 2474,
which was published in 1998, defines the DSCP
field, and then other ‘DiffServ’, differentiated
services, RFCs after it elaborate on the use
of the field. With IPP updated to DSCP, new
standard markings had to be decided upon.
Why is that? By having generally agreed upon
standard markings for different kinds of traffic,
QoS design and implementation is simplified,
QoS works better between ISPs and enterprises
because they agree upon the markings that
will be used, and there are other benefits
too. So, a few sets of industry-standard markings
were developed. Before we get into it, let
me say that it might feel a bit overwhelming
trying to remember all of these. I will include
flashcards to help you memorize them, but
really the only ones you need to remember
are some of the more common ones. I’ll point
those ones out after I’ve introduced all
of the markings. So, you should be aware of
the following standard markings. First, default
forwarding, DF. This is the marking for best
effort traffic, which doesn’t have any particular
QoS requirements. Then there is EF, Expedited
Forwarding. It’s used for traffic that requires
low loss, latency, and jitter, which is usually
voice traffic. Next is Assured Forwarding,
AF. This isn’t one marking, but a set of
12 standard values. Finally there is class
selector, CS, which is a set of 8 standard
values. CS provides backward compatibility
with IPP.
We won’t cover QoS configuration because
it’s not a CCNA exam topic, but let me show
you this. I configured a ‘class-map’ called
TEST. When configuring QoS, class maps are
used to identify which traffic you want to
match. I configured a MATCH statement, specifying
that I want to match traffic based on the
DSCP value in the IP header. Let’s check
out the options. At the top is the choice
to simply configure the DSCP value in decimal,
from 0 to 63. Then below that are the 12 AF
values. Notice on the right it shows the binary,
for example AF11 has a binary value of 001
010. Under that there are the CS values. Again,
the binary values are displayed on the right.
I said there are 8 CS values, but only 7 are
shown here. That’s because the other one,
CS0, is the same as DF, default forwarding,
000 000. Finally at the bottom is EF, expedited
forwarding. Okay, let’s look at each of
these in more detail.
First up, DF and EF. DF is used for best-effort
traffic. The recommended DSCP marking is 0.
So, all 6 of these bits will be set to 0.
To make things easier to understand as we
continue, I’ll write the decimal value of
each binary bit above. So, standard network
traffic like sending an email or downloading
a file will probably have 0 0 0 0 0 0 in the
DSCP field of the IP header, indicating that
it doesn’t require any special treatment.
Then there is EF, expedited forwarding. EF
is used for traffic that requires low loss,
latency, and jitter. Typically, voice traffic
is marked as EF. The DSCP marking for EF is
46. So, this is how it looks in binary, 1
0 1 1 1 0. Okay, so these two are pretty easy
to remember. DF is used for best-effort traffic,
and the DSCP value is 0. EF is used for traffic
requiring low-loss, low-latency, and low-jitter,
usually voice traffic, and the DSCP value
is 46. Now things will get a bit more complicated.
So we just looked at default, also called
DF, and EF. Now let’s look at AF, assured
forwarding. AF can be a little tricky to understand,
but I’ll try to explain it clearly.
AF defines four traffic classes. All packets
in a class have the same priority. A higher
class number means higher priority, their
packets will be forwarded with better service
than lower-priority packets. Then, within
each class there are three levels of drop
precedence. A higher drop precedence means
the packet is more likely to drop during congestion
due to WRED. Now, notice that I’ve set up
the 6 DSCP bits a little differently. First
up, in AF this bit on the end is always set
to 0. I’m not exactly sure the reason for
this, it might just be because the designers
of AF decided they didn’t need so many values.
These two bits in red represent the drop precedence.
And these three bits represent the class.
Now, when we write an AF value, it’s written
as AF X Y, with X being the decimal number
of the class and Y being the decimal number
of the drop precedence. Let’s take a look
at an example to see how to do it.
So, we have a binary DSCP value of 001 010.
As I said, in the AF system we write it as
AF X Y, with X being the decimal number of
the class and Y being the decimal number of
the drop precedence. To do that, we split
it up into two parts. Three bits for the class,
two bits for the drop precedence. So, the
decimal of the class is 1, and the decimal
of the drop precedence is also 1. So, this
is AF1 1, or AF11, you can call it whichever
you like. Now, really this is just a 6-bit
DSCP number. If I write the normal 6-bit decimal
values up top, 1 2 4 8 16 and 32, we can calculate
that this is DSCP 10. So, AF11 is the same
value as DSCP10. AF is just a set of standard
DSCP markings, which is easier to work with
than simply having 64 DSCP values with no
system of standard values.
Let’s do some more practice. Now we have
binary 001 100. What AF value is this? This
time it’s class 1, drop precedence 2. So
it’s AF1 2, or AF12. How could you write
this as a normal decimal DSCP value? Here
are the values of each bit again. In this
case, the DSCP value is also written as 12.
So, AF12 is the same as DSCP 12.
Here’s another one. Try to figure it out
on your own, what AF value is this? Also,
how could we write it as a normal decimal
DSCP value? Try to figure it out without me
showing you the value of each binary bit.
Okay, let’s check. Here are the values of
each bit. This is AF2 3, or AF23. Written
as a normal DSCP value it is DSCP 22. Hopefully
you were able to figure that out. If not that’s
fine, let’s practice a couple more times.
This time we have a binary DSCP value of 011
100. What AF value is this, and how is it
written as a normal DSCP value? Let’s check.
Here are the values of each bit. So, this
is AF3 2, or AF32. Written as a normal DSCP
value, it is DSCP 28. So, AF32 is the same
as DSCP 28.
Okay, here’s one more for practice. Again,
what’s the AF value, and how can you write
it as a normal DSCP value? Let’s check.
So, a class of 4 and a drop precedence of
3, so this is AF4 3, or AF43. Written as a
normal DSCP value, it is DSCP 38. So, AF43
is equivalent to DSCP 38. By the way, within
AF, 43 is the highest value. There is no class
5, 6, or 7. Okay, so you should be able to
convert between these AF numbers and DSCP
values. If you want a quick way to calculate
it without writing out the binary every time,
here’s the formula. 8X plus 2Y, again the
class is X and the drop precedence is Y. The
reason for this is that 8 is the lowest value
of the ‘X’ portion, and 2 is the lowest
value of the ‘Y’ portion. So to calculate
it it’s 8X plus 2Y. It’s always best to
understand the binary underneath it all, whether
you’re learning IPv4 addresses, subnetting,
IPv6, matching with ACLs, QoS, whatever. But
after understanding the binary, it’s also
nice to have some shortcuts like this, 8X
plus 2Y.
So, here’s a summary of all of the AF values.
4 classes with 3 drop precedence values each.
So, within these AF values traffic marked
as AF41 gets the best treatment. It’s in
the highest priority class, but has the lowest
drop precedence. On the other hand, traffic
marked as AF13 gets the worst treatment, being
in the lowest priority class with the highest
drop precedence. I will include flashcards
for all of these to test that you can convert
them from the AF values to the regular DSCP
values. I’m not expecting you to memorize
them, but you should be able to calculate
the DSCP value of a given AF value.
Okay, that’s all for AF. I hope my explanation
was clear. If not, feel free to ask questions.
Finally, let’s look at CS. Fortunately,
CS is actually quite simple.
CS, class selector, defines eight DSCP values
for backward compatibility with IPP. How does
that backward compatibility work? The three
bits that were added for DSCP are set to 0,
and the original IPP bits are used to make
8 possible values. So, here’s the DSCP field
again. Notice that the three bits on the right
are set to 0, and the three bits on the left,
the original IP precedence bits, can be either
0 or 1. Here are the decimal values of those
three bits, 1 2 and 4. So, IPP gives us values
from 0 through 7. The equivalent values in
CS are CS0, CS1, CS2, 3, 4, 5, 6, and 7. Very
simple. Now, you should also know the decimal
DSCP value of these. Although CS is a way
of organizing the DSCP field into a set of
8 values, they are still DSCP values. Fortunately
it is quite simple to convert them, it’s
just 8 multiplied by the CS number. CS0 is
0, CS1 is 8, CS2 is 16, CS3 is 24, CS4 is
32, CS5 is 40, CS6 is 48, and CS7 is 56. Okay,
that’s all for CS, quite simple.
Okay, so we’ve got DF, EF, AF, and CS. How
are we supposed to take those values and actually
use them? RFC 4954 was developed with the
help of Cisco to bring all of these values
together and standardize their use. Many specific
recommendations are given in the RFC, but
here are a few key ones. Voice traffic is
marked as EF, because it requires very low
delay, jitter, and loss. Interactive video
should be marked as AF4x, meaning AF41, 2,
or 3. Streaming video is marked as AF3x, high
priority data is AF2x, and best effort data
is marked as DF, a DSCP value of 0. There
are many more recommendations given within
the RFC, do a google search for it if you’re
interested. However, in the end it’s up
to the engineer designing the QoS policy of
the network which traffic will get which markings.
These are just standard recommendations.
Okay, let’s move on to take a quick look
at the topic of trust boundaries. The trust
boundary of a network defines where devices
trust and don’t trust the QoS markings of
received messages. If the markings are trusted,
that means the device will forward the message
without changing the markings. But if the
markings aren’t trusted, the device will
change the markings according to the configured
policy. So, for example let’s say the trust
boundary is here, at SW1. Phone1 sends a message
marked as EF and CoS5 to SW1. Note that CoS
is referring to the PCP field in the dot1q
header. You may hear it called CoS5 or PCP5,
you should be familiar with both terms. Anyway,
SW1 doesn’t trust the markings from phone1
because it’s from outside of the trust boundary.
So perhaps it changes the DSCP marking to
DF and the CoS marking to 0, before forwarding
it to R1, which forwards it on to R2, with
just the DF marking because there is no dot1q
header. Now, this configuration isn’t ideal.
Usually it’s best to trust the markings
from an IP phone because we want its traffic
to be high priority anyway.
If an IP phone is connected to the switchport,
it is recommended to move the trust boundary
to the IP phone. This is done via configuration
on the switch port connected to the IP phone,
by the way, not directly on the phone itself.
So, if a tech-savvy user is able to mark their
PC’s traffic with a high-priority marking
to get faster service, the marking will be
changed according to the configured policy.
But traffic sent from the phone itself will
be trusted by the switch. In this case, if
phone1 sends an EF and CoS5-marked message
SW1 will trust those markings and not change
them. On the other hand, if PC2 for example
sends an EF-marked packet, the switch should
not trust that, and for example it might change
the EF marking, DSCP 46, to DF, DSCP 0. We
don’t want data applications on the PC being
treated with the same priority as the voice
traffic from the phones. Okay, that’s all
for trust boundaries. You don’t need to
know how to configure them for the exam, but
just be aware of the concept of trust boundaries
and how they work.
Okay, that’s all for classification and
marking. Now let’s move on to queuing and
congestion management. I already introduced
it in the previous video, but there’s a
bit more to be covered for the CCNA. For review,
when a network device receives traffic at
a faster rate than it can forward the traffic
out of the appropriate interface, packets
are placed in that interface’s queue as
they wait to be forwarded. When the queue
becomes full, packets that don’t fit in
the queue are dropped, and this is called
tail drop. RED and WRED, which I already introduced,
drop packets early to avoid tail drop. Here’s
the image I showed last video. The router
is forwarding packets in an FIFO manner, but
the queue gets full and packets start getting
dropped. RED or WRED could help avoid this
by dropping packets earlier.
However, an essential part of QoS is the use
of multiple queues, not just a single queue.
And this is where classification really plays
a role. The device can match traffic based
on various factors, for the example the DSCP
marking in the IP header, but also many other
things, and then place the traffic in the
appropriate queue. However, the device is
only able to forward one frame out of an interface
at once, so a scheduler is used to decide
which queue traffic is forwarded from next.
Prioritization allows the scheduler to give
certain queues more priority than others.
So, this is where the power of QoS really
becomes clear. Here’s that same example
as before, however this time let’s say the
router’s interface forwarding the traffic
has been configured with multiple queues.
Here’s how it works. Ingress traffic is
received by the router. Ingress just means
incoming traffic, traffic entering the router.
Then it performs routing, meaning it decides
which interface to send it out of, as well
as other things like NAT if necessary. Then
it classifies the traffic and places it into
the appropriate queue. In this case there
are four queues and traffic is classified
and placed in a queue depending on, for example,
the DSCP marking. Then the scheduler decides
how much traffic to send from each queue,
in which order, and the router forwards the
traffic, one packet at a time. This is an
oversimplification, but its basically how
it works. After the router decides which interface
to forward the packet out of, it is classified,
queued, scheduled, and then transmitted.
A common scheduling method is weighted round-robin.
round robin means that packets are taken from
each queue in order, cyclically. And weighted
means that more data is taken from high priority
queues each time the scheduler reaches that
queue, so those queues get higher output.
Next, here’s a term you definitely should
know. CBWFQ, class-based weighted fair queuing,
is a popular method of scheduling, using a
weighted round-robin scheduler while guaranteeing
each queue a certain percentage of the interface’s
bandwidth during times of congestion. So,
let’s put these together. Here’s the process
again. Classify the traffic, place it in queues,
schedule it, and transmit. The device is using
a weighted round robin scheduler, sending
a certain amount of traffic from each queue
in cycles. On top of that, each queue gets
a guaranteed minimum amount of bandwidth,
even when the queues are congested. So, this
is getting a lot more advanced than just a
single output queue. But it’s still not
ideal. Specifically it’s not ideal for voice
and video traffic. Even if the traffic receives
a guaranteed minimum amount of bandwidth,
round-robin can add delay and jitter because
even the high-priority voice and video queues
have to wait their turn in the scheduler.
To solve that, we can configure LLQ, low latency
queuing. LLQ designates one, or more, queues
as strict priority queues. Strict priority
means that if there is traffic in the queue,
the scheduler will always take the next packet
from that queue, until it is empty. This is
very effective for reducing the delay and
jitter of voice and video traffic. As soon
as traffic enters the priority queue, the
scheduler will forward that traffic. So, here’s
that same diagram, but this time the top queue
is a strict priority queue. Currently there
is traffic in the queue, so the scheduler
will send all of that traffic before continuing
the weighted round-robin scheduling of the
other queues. But there’s a potential problem
here. LLQ has the downside of potentially
starving other queues if there is always traffic
in the designated strict priority queue. The
other queues might never get a turn to send
traffic. Policing, which I will cover in the
next slide, can control the amount of traffic
allowed in the strict priority queue so that
it can’t take all of the link’s bandwidth.
Okay, so in this section we expanded on the
idea of queuing introduced in the previous
video and examined the use of multiple queues.
A router classifies traffic, for example by
looking at the DSCP value, then places it
in the appropriate queue. The scheduler, for
example using weighted round-robin logic,
forwards packets from each queue in a cycle.
With the addition of LLQ, a strict priority
queue can be used to immediately forward high
priority packets. And by the way, within each
of these queues congestion prevention tools
like RED or WRED can be used to avoid tail
drop if that queue becomes full.
Okay, here are the final topics for today,
shaping and policing. At the CCNA level you
basically just have to understand what these
two QoS functions do, so I’ll summarize
them in one slide. Traffic shaping and policing
are both used to control the rate of traffic.
In the previous examples of queuing and scheduling
we assumed that the interfaces are operating
at full capacity, or beyond full capacity
which is why packets need to be queued. However
there are situations in which it is desirable
to limit the rate of traffic to below the
actual maximum capacity of the link. Shaping
buffers traffic in a queue if the traffic
rate goes over the configured rate. So, this
is the same concept I just demonstrated, however
instead of the actual capacity of the link
being the limiting factor, it’s a maximum
traffic rate configured on the link. Policing
isn’t as polite as shaping. It drops traffic
if the traffic rate goes over the configured
rate. However there is some flexibility. Burst
traffic over the configured rate is allowed
for a short period of time. This accommodates
data applications which are ‘bursty’ in
nature. Instead of a constant stream of data,
they tend to send data in bursts. Just like
the policed data rate, the amount of burst
traffic allowed is also configurable. And
in both cases, classification can be used
to allow for different rates for different
kinds of traffic. Now, why would you want
to limit the rate traffic is sent or received?
To demonstrate one common case, here’s a
sample network. A customer router is connected
to an ISP, Internet Service Provider, router.
The customer configures shaping outbound on
the G0/0 interface of the router, and the
ISP configures policing inbound on the G0/0
interface of the ISP router. Can you think
of a reason why this might be done? Although
the physical interfaces are gigabit ethernet,
1000 megabits per second, perhaps this customer
is paying for a 300 megabit per second connection.
So the ISP says, you paid for a 300 megabit
per second connection, so I’m going to police
incoming traffic to 300 megabits per second.
The customer then decides, if I send traffic
faster than 300 megabits per second it will
be dropped by the ISP, so I will shape the
outgoing traffic to 300 megabits per second.
There are various possible uses for shaping
and policing, but this is a common use of
these tools.
Okay, that was a lot of material to cover.
Let’s review what we covered before moving
on to the quiz. First, we covered classification
and marking. Classification means identifying
different kinds of traffic so that you can
then treat it with an appropriate level of
priority. Marking refers to setting the values
of certain fields in the Layer 2 and Layer
3 headers for use in classification. We covered
the CoS field in the dot1q tag, then the ToS
byte in the IP header, including IP Precedence
and differentiated services code point. I
also introduced the concept of trust boundaries.
I then expanded on queuing and congestion
management, which I introduced in the last
video. I introduced the concept of multiples
queues, weighted round-robin scheduling, CBWFQ,
and LLQ. Marking a packet as EF, for example,
doesn’t actually do anything on its own.
You have to configure tools like CBWFQ and
LLQ to make the devices treat those packets
as high priority. Finally I introduced shaping
and policing, which are both tools to control
the rate traffic is sent or received. Watch
until the end of the quiz for a bonus practice
question from Boson Software’s ExSim for
CCNA. Okay, let’s go to quiz question 1.
SLIDE30
Which of the following CoS markings are consistent
with standard practice? Select three. Okay,
pause the video now to select the correct
answers.
The answers are B, CoS 0 for best effort.
D, CoS 5 for voice. And E, CoS 4 for video.
Here’s that chart again showing the PCP
values, which is another name for the CoS
values, and their traffic types. In your networks
you don’t have to follow this marking scheme,
but this is standard practice. Okay, let’s
go to question 2.
SLIDE31
What bit pattern would you find in the DSCP
field of a packet marked as EF? Pause the
video now to think about the answer.
Okay, the answer is D, 101 110. Here it is,
showing the decimal value of each bit. EF,
which is used for traffic requiring low delay,
jitter, and loss, has a decimal DSCP value
of 46, so the bit pattern is 101 110. Okay,
let’s go to question 3.
SLIDE32
Which of the following AF markings provides
the best service? Pause the video now to think
about the answer.
The answer is B, AF41. Here is the table of
AF markings again. AF41 is in the highest
priority class and it has the lowest drop
precedence. AF43 is also in the high priority
queue, but it has a higher drop precedence.
AF51 and AF61 are not real AF markings, AF
only uses classes 1, 2, 3, and 4. Okay, let’s
go to quiz question 4.
SLIDE33
Which of the following statements represents
general best practice regarding QoS? Pause
the video now to think about the answer.
Okay, the answer is A, trust markings from
IP phones, don’t trust markings from PCs.
IP phones will typically mark their voice
traffic as EF and CoS5, and those markings
should be trusted because voice traffic requires
low delay, jitter, and loss. Markings from
PCs should not be trusted, though. Traffic
from data applications on PCs should be marked
as low priority so that it doesn’t fill
up the high priority queues reserved for voice
traffic. Now, apps like Zoom or WebEx used
on a PC do need high priority service, but
we can mark those packets at the switch or
router. Okay, let’s go to question 5.
SLIDE34
Which of the following creates a strict priority
queue for data that requires low delay, jitter,
and loss? Pause the video now to think about
the answer.
there are packets in that queue the scheduler
will always forward them next, before traffic
in the other queues. Okay, that’s all for
the quiz. Now let’s take a look at a bonus
question in Boson Software’s ExSim for CCNA.
0:39:58.325,1193:02:47.295
Okay, the answer is B, LLQ. Low latency queuing
creates a strict priority queue, meaning if
There are supplementary materials for this
video. There is a flashcard deck to use with
the software ‘Anki’. There will also be
a packet tracer practice lab so you can get
some hands-on practice. Now, QoS configuration
isn’t actually part of the CCNA exam and
we didn’t cover it in this video. But I
think it will be beneficial to see how it’s
configured, so I’ll do a quick demo. That
will be in the next video.